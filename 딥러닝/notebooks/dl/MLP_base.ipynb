{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [MLP_base] Standardized Baseline\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµì˜ **ê¸°ì¤€ì (Reference Point)**ì´ ë˜ëŠ” Baseline ëª¨ë¸ì…ë‹ˆë‹¤.  \n",
                "ê¸°êµë¥¼ ë¶€ë¦¬ì§€ ì•Šì€ **\"ê°€ì¥ ë‹¨ìˆœí•œ êµ¬ì¡°\"**ë¡œ, ë°ì´í„°ê°€ ê°€ì§„ ê¸°ë³¸ì ì¸ ì˜ˆì¸¡ ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ“Œ í•µì‹¬ êµ¬ì„± (Configuration)\n",
                "1.  **Simple Architecture**: Input, Hidden(2ì¸µ), Outputìœ¼ë¡œë§Œ êµ¬ì„±ëœ **BasicMLP**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (No DropOut, No BatchNorm)\n",
                "2.  **Standard Pipeline**: `MLP_enhance`ì™€ ë™ì¼í•œ ë°ì´í„°(Anchors ì œê±°, Raw Distribution) ê·œê²©ì„ ë”°ë¦…ë‹ˆë‹¤. --> **ê³µì •í•œ ë¹„êµ ë³´ì¥**\n",
                "3.  **Fast Execution**: Epochs 10íšŒ ì„¤ì •ì„ í†µí•´ ë¹ ë¥´ê²Œ ê¸°ì¤€ ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ëª¨ë¸ ì •ì˜ (Libraries & Model)\n",
                "\n",
                "- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: PyTorch, Pandas ë“± í•„ìˆ˜ ë„êµ¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
                "- **BasicMLP**: 3-Layer(Input-Hidden-Output)ë¡œ êµ¬ì„±ëœ ê°€ì¥ ê¸°ë³¸ì ì¸ ì‹ ê²½ë§ ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
                "- **íŠ¹ì§•**: Dropoutì´ë‚˜ Batch Normalization ì—†ì´ ìˆœìˆ˜í•œ Fully Connected Layerë¡œë§Œ êµ¬ì„±ë©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import pathlib\n",
                "\n",
                "sys.path.append(os.path.abspath(\"../../\"))\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "# [MPS Acceleration]\n",
                "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
                "print(f\"ğŸš€ Using Device: {device}\")\n",
                "\n",
                "# [Model Import] BasicMLP (From centralized definitions)\n",
                "from models.model_definitions import BasicMLP\n",
                "print(\"âœ… BasicMLP Model Imported.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Data Loading)\n",
                "\n",
                "- **Clean Data Pipeline**: `MLP_enhance`ì™€ ë™ì¼í•˜ê²Œ ì •ì œëœ íŒŒì¼€ì´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "- **Type Casting**: ID ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë§¤ì¹­ ì •í™•ë„ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.\n",
                "- **Inner Join**: Featureì™€ Labelì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë§Œ ë³‘í•©í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('ğŸ“‚ Loading Data...')\n",
                "base_path = \"/Users/gimdabin/SKN23-2nd-3Team/data/processed/\"\n",
                "\n",
                "# Load Parquet Files\n",
                "features = pd.read_parquet(base_path + \"features_ml_clean.parquet\")\n",
                "labels = pd.read_parquet(base_path + \"labels.parquet\")\n",
                "\n",
                "# Type Casting\n",
                "features['user_id'] = features['user_id'].astype(str)\n",
                "labels['user_id'] = labels['user_id'].astype(str)\n",
                "\n",
                "# Merge (Inner Join)\n",
                "data = features.merge(labels, on=['user_id', 'anchor_time'], how='inner')\n",
                "data['target'] = (data['label'] == 'm2').astype(int)\n",
                "\n",
                "# Features & Target Split\n",
                "feature_cols = [c for c in features.columns if c not in ['user_id', 'anchor_time']]\n",
                "X = data[feature_cols].copy().fillna(0)\n",
                "y = data['target'].values\n",
                "\n",
                "print(f\"âœ… Data Loaded. Shape: {data.shape}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ë°ì´í„° ë¶„í•  (Time-based Split)\n",
                "\n",
                "- **Time-based Split**: `split` ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ì…‹ì„ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
                "- **Consistency**: ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ë™ì¼í•œ ë°ì´í„° ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ë¹„êµì˜ ê³µì •ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert \"split\" in data.columns, \"Missing 'split' column!\"\n",
                "\n",
                "split = data[\"split\"].astype(str).str.lower().values\n",
                "train_mask = split == \"train\"\n",
                "val_mask   = np.isin(split, [\"val\", \"valid\", \"validation\"])\n",
                "test_mask  = split == \"test\"\n",
                "\n",
                "X_train, y_train = X.loc[train_mask].values, y[train_mask]\n",
                "X_val, y_val     = X.loc[val_mask].values, y[val_mask]\n",
                "X_test, y_test   = X.loc[test_mask].values, y[test_mask]\n",
                "\n",
                "print(f\"ğŸ”¹ Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
                "print(f\"ğŸ“Š Train Base Rate: {y_train.mean():.4f}\")\n",
                "print(f\"ğŸ“Š Val   Base Rate: {y_val.mean():.4f}\")\n",
                "print(f\"ğŸ“Š Test  Base Rate: {y_test.mean():.4f}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (Preprocessing)\n",
                "\n",
                "- **Standard Scaling**: Train Setì˜ í†µê³„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
                "- **No SMOTE**: Baselineì€ ë°ì´í„°ë¥¼ ì™œê³¡í•˜ì§€ ì•Šê³  ìˆëŠ” ê·¸ëŒ€ë¡œ(Raw) í•™ìŠµí•˜ì—¬ ì‹¤ì œ ì„±ëŠ¥ì˜ í•˜í•œì„ ì„ ì¸¡ì •í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "BATCH_SIZE = 256\n",
                "train_loader = DataLoader(TensorDataset(torch.FloatTensor(X_train_scaled), torch.FloatTensor(y_train)), batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader = DataLoader(TensorDataset(torch.FloatTensor(X_val_scaled), torch.FloatTensor(y_val)), batch_size=BATCH_SIZE)\n",
                "test_loader = DataLoader(TensorDataset(torch.FloatTensor(X_test_scaled), torch.FloatTensor(y_test)), batch_size=BATCH_SIZE)\n",
                "\n",
                "print(\"âœ… Preprocessing Compelete (Raw Distribution).\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Fast Config)\n",
                "\n",
                "- **Hidden Dim**: 128 (ê°€ë²¼ìš´ ëª¨ë¸)\n",
                "- **Epochs**: 10 (ë¹ ë¥¸ ë²¤ì¹˜ë§ˆí‚¹)\n",
                "- **Optimzier**: Adam (ê¸°ë³¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_params = {\n",
                "    'lr': 0.001,\n",
                "    'weight_decay': 0.00001,\n",
                "    'hidden_dim': 128,\n",
                "    'epochs': 10,\n",
                "    'optimizer': 'Adam'\n",
                "}\n",
                "print(f\"âš™ï¸ Config Loaded: {best_params}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ëª¨ë¸ í•™ìŠµ (Training Loop)\n",
                "\n",
                "- **Training**: `BasicMLP` ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
                "- **Validation**: ë§¤ Epochë§ˆë‹¤ ì„±ëŠ¥ì„ ì²´í¬í•˜ì§€ë§Œ, Baselineì´ë¯€ë¡œ ë³„ë„ì˜ ë³µì¡í•œ Early Stoppingì€ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = BasicMLP(X.shape[1], hidden_dim=best_params['hidden_dim']).to(device)\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
                "\n",
                "print(\"ğŸš€ Starting Baseline Training...\")\n",
                "\n",
                "for epoch in range(best_params['epochs']):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for inputs, targets in train_loader:\n",
                "        inputs, targets = inputs.to(device), targets.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs).squeeze()\n",
                "        loss = criterion(outputs, targets)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "        \n",
                "    # Validation Log\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    with torch.no_grad():\n",
                "        for inputs, targets in val_loader:\n",
                "            inputs, targets = inputs.to(device), targets.to(device)\n",
                "            outputs = model(inputs).squeeze()\n",
                "            val_loss += criterion(outputs, targets).item()\n",
                "            \n",
                "    print(f'Epoch {epoch+1:02d}/{best_params[\"epochs\"]}: Train Loss {epoch_loss/len(train_loader):.4f}, Val Loss {val_loss/len(val_loader):.4f}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. ëª¨ë¸ í‰ê°€ (Evaluation)\n",
                "\n",
                "- **Comparison**: ì´ ëª¨ë¸ì˜ ì„±ëŠ¥ ì ìˆ˜ëŠ” ë‹¤ë¥¸ ê³ ê¸‰ ëª¨ë¸ë“¤(`Enhance`, `Advanced`)ì´ ë°˜ë“œì‹œ ë„˜ì–´ì•¼ í•  ê¸°ì¤€ì„ ì…ë‹ˆë‹¤.\n",
                "- **Metrics**: ROC-AUC, Precision, Lift ë“±ì„ ì¸¡ì •í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from app.utils.metrics import evaluate_churn_metrics\n",
                "\n",
                "model.eval()\n",
                "all_probs = []\n",
                "all_true = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for inputs, targets in test_loader:\n",
                "        inputs = inputs.to(device)\n",
                "        outputs = model(inputs).squeeze()\n",
                "        probs = torch.sigmoid(outputs)\n",
                "        all_probs.extend(probs.cpu().numpy())\n",
                "        all_true.extend(targets.numpy())\n",
                "\n",
                "metrics_result = evaluate_churn_metrics(\n",
                "    y_true=np.array(all_true),\n",
                "    y_prob=np.array(all_probs)\n",
                ")\n",
                "\n",
                "# Ranking ë¶„ë¦¬\n",
                "if 'ranking' in metrics_result:\n",
                "    ranking_list = metrics_result.pop('ranking')\n",
                "    top_k_df = pd.DataFrame(ranking_list)\n",
                "else:\n",
                "    top_k_df = pd.DataFrame()\n",
                "\n",
                "metrics = metrics_result\n",
                "\n",
                "display(Markdown(\"### ğŸ“Š Baseline Performance\"))\n",
                "display(pd.DataFrame(list(metrics.items()), columns=['KPI', 'Value']))\n",
                "display(Markdown(\"### ğŸ“ˆ Top K% Ranking\"))\n",
                "display(top_k_df)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. ê²°ê³¼ ì €ì¥ (Artifact Saving)\n",
                "\n",
                "- **Artifacts**: ëª¨ë¸ í‰ê°€ ê²°ê³¼ë¥¼ í‘œì¤€í™”ëœ JSON í¬ë§·ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
                "- **Path**: `models/eval/dlmlp_base/`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import pathlib\n",
                "\n",
                "# [Correct Path] dlmlp_base\n",
                "MODEL_ID = \"dlmlp_base\"\n",
                "EVAL_DIR = pathlib.Path(f\"../../models/eval/{MODEL_ID}\")\n",
                "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Model Card\n",
                "model_card = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"display_name\": \"MLP Base (Baseline)\",\n",
                "    \"category\": \"DL\",\n",
                "    \"split\": \"test\"\n",
                "}\n",
                "with open(EVAL_DIR / \"model_card.json\", \"w\") as f:\n",
                "    json.dump(model_card, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "# PR Metrics\n",
                "pr_metrics = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"pr_auc\": float(metrics.get(\"PR-AUC (Average Precision)\", 0.0))\n",
                "}\n",
                "with open(EVAL_DIR / \"pr_metrics.json\", \"w\") as f:\n",
                "    json.dump(pr_metrics, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "# Top K Metrics\n",
                "current_base_rate = float(np.mean(all_true)) if 'all_true' in locals() else 0.0\n",
                "metrics_by_k = []\n",
                "if not top_k_df.empty:\n",
                "    for _, row in top_k_df.iterrows():\n",
                "        k_str = str(row.get('Top_K', '0')).replace('%', '')\n",
                "        try: k_val = int(k_str)\n",
                "        except: k_val = 0\n",
                "        metrics_by_k.append({\n",
                "            \"k_pct\": k_val,\n",
                "            \"precision_at_k\": float(row.get('Precision', 0.0)),\n",
                "            \"recall_at_k\": float(row.get('Recall', 0.0)),\n",
                "            \"lift_at_k\": float(row.get('Lift', 0.0))\n",
                "        })\n",
                "\n",
                "topk_output = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"base_rate\": current_base_rate,\n",
                "    \"metrics_by_k\": metrics_by_k\n",
                "}\n",
                "with open(EVAL_DIR / \"topk_metrics.json\", \"w\") as f:\n",
                "    json.dump(topk_output, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "print(f\"âœ… All artifacts saved to {EVAL_DIR} (LG Style Format)\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "churn_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}