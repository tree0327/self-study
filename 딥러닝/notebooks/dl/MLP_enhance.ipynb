{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [MLP_enhance] Fast Baseline Model\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ **ì†ë„ì™€ íš¨ìœ¨ì„±**ì„ ì¤‘ì‹œí•˜ëŠ” **Fast Baseline** ëª¨ë¸ êµ¬ì¶•ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  \n",
                "ë³µì¡í•œ ì•™ìƒë¸”ì´ë‚˜ ë¬´ê±°ìš´ í•™ìŠµ ê³¼ì •ì„ ë°°ì œí•˜ê³ , **ë‹¨ì¼ ëª¨ë¸**ë¡œ ë¹ ë¥´ê²Œ ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ“Œ í•µì‹¬ ì „ëµ (Key Strategy)\n",
                "1.  **Clean Data Pipeline**: `anchors` í…Œì´ë¸” ë³‘í•© ê³¼ì •ì„ ì œê±°í•˜ê³ , ì •ì œëœ `features_ml_clean`ê³¼ `labels`ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¬´ê²°ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.\n",
                "2.  **Use Raw Distribution**: **SMOTE(ì˜¤ë²„ìƒ˜í”Œë§)**ë¥¼ ì œê±°í•˜ê³  ì›ë³¸ ë°ì´í„° ë¶„í¬ ê·¸ëŒ€ë¡œ í•™ìŠµí•˜ì—¬, ì‹¤ì œ í™˜ê²½ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì¡°ê±´ì—ì„œ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
                "3.  **Fast Hyperparameters**: Epochsë¥¼ 10íšŒë¡œ ì œí•œí•˜ê³ , ëª¨ë¸ í¬ê¸°ë¥¼ ìµœì í™”(Hidden 128)í•˜ì—¬ ì‹¤í–‰ ì†ë„ë¥¼ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¤ì •\n",
                "\n",
                "- **ì‹œìŠ¤í…œ ê²½ë¡œ**: í”„ë¡œì íŠ¸ Rootë¥¼ ì¶”ê°€í•˜ì—¬ ì»¤ìŠ¤í…€ ëª¨ë“ˆ í˜¸ì¶œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
                "- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: PyTorch, Pandas, Numpy ë“± í•„ìˆ˜ íŒ¨í‚¤ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
                "- **ê°€ì†ê¸° í™•ì¸**: Mac M1/M2/M3(MPS) ë˜ëŠ” CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
                "- **ëª¨ë¸ ë¡œë“œ**: `models/model_definitions.py`ì—ì„œ `MLP_enhance` í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import pathlib\n",
                "\n",
                "# Root ê²½ë¡œ ì¡ê¸°\n",
                "sys.path.append(os.path.abspath(\"../../\"))\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "# [MPS Acceleration] ê°€ì† ì§€ì› í™•ì¸\n",
                "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
                "print(f\"ğŸš€ Using Device: {device}\")\n",
                "\n",
                "# [Model Import] MLP_enhance ëª¨ë¸ ë¡œë“œ\n",
                "from models.model_definitions import MLP_enhance\n",
                "print(\"âœ… MLP_enhance Model Imported.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Data Loading)\n",
                "\n",
                "- **Parquet ë¡œë“œ**: Featureì™€ Label ë°ì´í„°ë¥¼ ê°ê° ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
                "- **Type Casting**: `user_id` ë§¤ì¹­ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
                "- **Inner Join**: Featureì™€ Labelì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ìœ íš¨í•œ ìƒ˜í”Œë§Œ ë³‘í•©í•©ë‹ˆë‹¤. (`anchors` ë³‘í•© ì œê±°ë¨)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('ğŸ“‚ Loading Data...')\n",
                "base_path = \"/Users/gimdabin/SKN23-2nd-3Team/data/processed/\"\n",
                "\n",
                "# Features & Labels ë¡œë“œ\n",
                "features = pd.read_parquet(base_path + \"features_ml_clean.parquet\")\n",
                "labels = pd.read_parquet(base_path + \"labels.parquet\")\n",
                "\n",
                "# ID ì»¬ëŸ¼ íƒ€ì… í†µì¼\n",
                "features['user_id'] = features['user_id'].astype(str)\n",
                "labels['user_id'] = labels['user_id'].astype(str)\n",
                "\n",
                "# ë°ì´í„° ë³‘í•© (Inner Join)\n",
                "data = features.merge(labels, on=['user_id', 'anchor_time'], how='inner')\n",
                "data['target'] = (data['label'] == 'm2').astype(int)\n",
                "\n",
                "# X(Features)ì™€ y(Target) ë¶„ë¦¬\n",
                "feature_cols = [c for c in features.columns if c not in ['user_id', 'anchor_time']]\n",
                "X = data[feature_cols].copy().fillna(0)\n",
                "y = data['target'].values\n",
                "\n",
                "print(f\"âœ… Data Concatenation Complete. Shape: {data.shape}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ë°ì´í„° ë¶„í•  (Time-based Split)\n",
                "\n",
                "- **Time-based Split**: ë¯¸ë˜ ë°ì´í„° ì°¸ì¡°(Leakage)ë¥¼ ë§‰ê¸° ìœ„í•´ ì‹œê°„ ìˆœì„œê°€ ì ìš©ëœ `split` ì»¬ëŸ¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "- **ë°ì´í„°ì…‹ êµ¬ë¶„**: Train(í•™ìŠµ), Val(ê²€ì¦), Test(ìµœì¢… í‰ê°€)ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
                "- **ë¶„í¬ í™•ì¸**: ê° Setë³„ íƒ€ê²Ÿ ë¹„ìœ¨(Base Rate)ì„ ì¶œë ¥í•˜ì—¬ ë°ì´í„° ì¹˜ìš°ì¹¨ì„ í™•ì¸í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert \"split\" in data.columns, \"Missing 'split' column!\"\n",
                "\n",
                "split = data[\"split\"].astype(str).str.lower().values\n",
                "train_mask = split == \"train\"\n",
                "val_mask   = np.isin(split, [\"val\", \"valid\", \"validation\"])\n",
                "test_mask  = split == \"test\"\n",
                "\n",
                "X_train, y_train = X.loc[train_mask].values, y[train_mask]\n",
                "X_val, y_val     = X.loc[val_mask].values, y[val_mask]\n",
                "X_test, y_test   = X.loc[test_mask].values, y[test_mask]\n",
                "\n",
                "print(f\"ğŸ”¹ Train Set: {len(X_train)} samples\")\n",
                "print(f\"ğŸ”¹ Val   Set: {len(X_val)} samples\")\n",
                "print(f\"ğŸ”¹ Test  Set: {len(X_test)} samples\")\n",
                "\n",
                "print(f\"ğŸ“Š Train Base Rate: {y_train.mean():.4f}\")\n",
                "print(f\"ğŸ“Š Val   Base Rate: {y_val.mean():.4f}\")\n",
                "print(f\"ğŸ“Š Test  Base Rate: {y_test.mean():.4f}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ë° ë¡œë” ìƒì„± (Scaling & Loader)\n",
                "\n",
                "- **StandardScaler**: í‰ê·  0, ë¶„ì‚° 1ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤. `fit`ì€ ì˜¤ì§ **Train Set**ì—ë§Œ ì ìš©í•©ë‹ˆë‹¤.\n",
                "- **No SMOTE**: ì¸ìœ„ì ì¸ ì˜¤ë²„ìƒ˜í”Œë§ì„ ì œê±°í•˜ê³ , ì‹¤ì œ ë°ì´í„° ë¶„í¬(Raw Distribution)ë¥¼ ê·¸ëŒ€ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
                "- **DataLoader**: ë°°ì¹˜(Batch) ë‹¨ìœ„ í•™ìŠµì„ ìœ„í•´ PyTorch DataLoaderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scaling\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# DataLoader Setup\n",
                "BATCH_SIZE = 256\n",
                "train_loader = DataLoader(TensorDataset(torch.FloatTensor(X_train_scaled), torch.FloatTensor(y_train)), batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader = DataLoader(TensorDataset(torch.FloatTensor(X_val_scaled), torch.FloatTensor(y_val)), batch_size=BATCH_SIZE)\n",
                "test_loader = DataLoader(TensorDataset(torch.FloatTensor(X_test_scaled), torch.FloatTensor(y_test)), batch_size=BATCH_SIZE)\n",
                "\n",
                "print(\"âœ… Preprocessing Complete (No SMOTE, Raw Distribution).\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Fast Config)\n",
                "\n",
                "ë¹ ë¥¸ ì‹¤í—˜ê³¼ Baseline ìˆ˜ë¦½ì„ ìœ„í•´ ê²½ëŸ‰í™”ëœ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "\n",
                "- **Epochs**: 10 (ì¶©ë¶„í•œ ìˆ˜ë ´ í™•ì¸ ê°€ëŠ¥)\n",
                "- **Hidden Dim**: 128 (ëª¨ë¸ ë³µì¡ë„ ìµœì í™”)\n",
                "- **Optimizer**: Adam (ì•ˆì •ì ì¸ ìˆ˜ë ´)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_params = {\n",
                "    'lr': 0.001,\n",
                "    'weight_decay': 0.00001,\n",
                "    'hidden_dim': 128,\n",
                "    'dropout_rate': 0.3,\n",
                "    'epochs': 10,\n",
                "    'activation': 'relu',\n",
                "    'optimizer': 'Adam'\n",
                "}\n",
                "print(f\"âš™ï¸ Applied Fast Hyperparameters: {best_params}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ëª¨ë¸ í•™ìŠµ (Model Training)\n",
                "\n",
                "- **Training Loop**: ì„¤ì •ëœ Epochë§Œí¼ ë°˜ë³µí•˜ë©° ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
                "- **Loss Function**: ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•´ `BCEWithLogitsLoss`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "- **Monitoring**: ë§¤ Epochë§ˆë‹¤ Train Lossì™€ Val Lossë¥¼ ì¶œë ¥í•˜ì—¬ ê³¼ì í•© ì—¬ë¶€ë¥¼ ì²´í¬í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = MLP_enhance(\n",
                "    X.shape[1], \n",
                "    hidden_dim=best_params['hidden_dim'], \n",
                "    dropout_rate=best_params['dropout_rate'], \n",
                "    activation=best_params['activation']\n",
                ").to(device)\n",
                "\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
                "\n",
                "print(\"ğŸš€ Starting Training (Fast Mode)...\")\n",
                "\n",
                "for epoch in range(best_params['epochs']):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for inputs, targets in train_loader:\n",
                "        inputs, targets = inputs.to(device), targets.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs).squeeze()\n",
                "        loss = criterion(outputs, targets)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    # Validation Loss Check\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    with torch.no_grad():\n",
                "        for inputs, targets in val_loader:\n",
                "            inputs, targets = inputs.to(device), targets.to(device)\n",
                "            outputs = model(inputs).squeeze()\n",
                "            val_loss += criterion(outputs, targets).item()\n",
                "    \n",
                "    print(f'Epoch {epoch+1:02d}/{best_params[\"epochs\"]}: Train Loss {epoch_loss/len(train_loader):.4f}, Val Loss {val_loss/len(val_loader):.4f}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. ëª¨ë¸ í‰ê°€ (Evaluation)\n",
                "\n",
                "- **Test Set Evaluation**: ê³¼ì í•©ë˜ì§€ ì•Šì€ ìˆœìˆ˜í•œ Test ë°ì´í„°ë¡œ ìµœì¢… ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
                "- **Metrics**: ROC-AUC, PR-AUC, Precision, Recall ë“± ì£¼ìš” ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
                "- **Ranking**: ìƒìœ„ n% ìœ ì €ì— ëŒ€í•œ ë¦¬í”„íŠ¸(Lift) ì„±ëŠ¥ì„ í™•ì¸í•˜ì—¬ ë§ˆì¼€íŒ… íš¨ìš©ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from app.utils.metrics import evaluate_churn_metrics\n",
                "\n",
                "print(\"Evaluating on Test Set...\")\n",
                "model.eval()\n",
                "all_probs = []\n",
                "all_true = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for inputs, targets in test_loader:\n",
                "        inputs = inputs.to(device)\n",
                "        outputs = model(inputs).squeeze()\n",
                "        probs = torch.sigmoid(outputs)\n",
                "        all_probs.extend(probs.cpu().numpy())\n",
                "        all_true.extend(targets.numpy())\n",
                "\n",
                "metrics_result = evaluate_churn_metrics(\n",
                "    y_true=np.array(all_true),\n",
                "    y_prob=np.array(all_probs)\n",
                ")\n",
                "\n",
                "# Ranking ë¶„ë¦¬\n",
                "if 'ranking' in metrics_result:\n",
                "    ranking_list = metrics_result.pop('ranking')\n",
                "    top_k_df = pd.DataFrame(ranking_list)\n",
                "else:\n",
                "    top_k_df = pd.DataFrame()\n",
                "\n",
                "metrics = metrics_result\n",
                "\n",
                "display(Markdown(\"### ğŸ“Š Fast Baseline Performance\"))\n",
                "display(pd.DataFrame(list(metrics.items()), columns=['KPI', 'Value']))\n",
                "display(Markdown(\"### ğŸ“ˆ Top K% Ranking\"))\n",
                "display(top_k_df)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. ê²°ê³¼ ì €ì¥ (Artifact Saving)\n",
                "\n",
                "- **JSON Export**: ëª¨ë¸ í‰ê°€ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í‘œì¤€í™”ëœ JSON í¬ë§·ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
                "- **Path**: `models/eval/dlmlp_enhance/`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import pathlib\n",
                "\n",
                "MODEL_ID = \"dlmlp_enhance\"\n",
                "EVAL_DIR = pathlib.Path(f\"../../models/eval/{MODEL_ID}\")\n",
                "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Model Card\n",
                "model_card = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"display_name\": \"MLP Enhance (Fast Baseline)\",\n",
                "    \"category\": \"DL\",\n",
                "    \"split\": \"test\"\n",
                "}\n",
                "with open(EVAL_DIR / \"model_card.json\", \"w\") as f:\n",
                "    json.dump(model_card, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "# PR Metrics\n",
                "pr_metrics = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"pr_auc\": float(metrics.get(\"PR-AUC (Average Precision)\", 0.0))\n",
                "}\n",
                "with open(EVAL_DIR / \"pr_metrics.json\", \"w\") as f:\n",
                "    json.dump(pr_metrics, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "# Top K Metrics\n",
                "current_base_rate = float(np.mean(all_true)) if 'all_true' in locals() else 0.0\n",
                "metrics_by_k = []\n",
                "if not top_k_df.empty:\n",
                "    for _, row in top_k_df.iterrows():\n",
                "        k_str = str(row.get('Top_K', '0')).replace('%', '')\n",
                "        try: k_val = int(k_str)\n",
                "        except: k_val = 0\n",
                "        metrics_by_k.append({\n",
                "            \"k_pct\": k_val,\n",
                "            \"precision_at_k\": float(row.get('Precision', 0.0)),\n",
                "            \"recall_at_k\": float(row.get('Recall', 0.0)),\n",
                "            \"lift_at_k\": float(row.get('Lift', 0.0))\n",
                "        })\n",
                "\n",
                "topk_output = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"base_rate\": current_base_rate,\n",
                "    \"metrics_by_k\": metrics_by_k\n",
                "}\n",
                "with open(EVAL_DIR / \"topk_metrics.json\", \"w\") as f:\n",
                "    json.dump(topk_output, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "print(f\"âœ… All artifacts saved to {EVAL_DIR} (LG Style Format)\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "churn_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
